% !TEX program = pdflatex
% Báo Cáo Môn: Data Mining
% Đề Tài: Cải Thiện Apriori
% Data Mining Project 2024-2025

\documentclass[a4paper,13pt]{report}

% Packages for Vietnamese language support
\usepackage[utf8]{inputenc}
\usepackage[T5]{fontenc}
\usepackage[vietnamese]{babel}

% Page setup (matches Word requirements)
\usepackage[a4paper,margin=0.7in,headheight=0.4in]{geometry}
\usepackage{setspace}
\onehalfspacing

% Packages
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{float}
\usepackage{longtable}
\usepackage{multirow}

% Font setup
\usepackage{mathptmx}
\usepackage{helvet}
\usepackage{courier}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray},
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{orange},
    backgroundcolor=\color{gray!10},
    showstringspaces=false
}

% Hyperlink setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=cyan,
    citecolor=green,
}

% Page style
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\textbf{CẢI THIỆN APRIORI -- Data Mining}}
\fancyhead[R]{\thepage}
\fancyfoot[C]{\small Năm học 2024 - 2025}

% Chapter formatting
\titleformat{\chapter}
  {\normalfont\huge\bfseries}{\chaptername\ \thechapter}{20pt}{\Huge}

% Graphics path
\graphicspath{{../../../charts/}}

% =============================================================================
% COVER PAGE
% =============================================================================
\begin{document}

\begin{titlepage}
\centering

% ===== Header =====
{\Large \textbf{TRƯỜNG ĐẠI HỌC NÔNG LÂM TP. HỒ CHÍ MINH}}\\[0.3cm]
{\Large \textbf{KHOA CÔNG NGHỆ THÔNG TIN}}\\[0.5cm]

\rule{0.6\textwidth}{0.4pt}

\vspace{1.8cm}

% ===== Title =====
{\LARGE \textbf{BÁO CÁO}}\\[1cm]

{\Large \textbf{CHỦ ĐỀ:} \textit{CẢI THIỆN THUẬT TOÁN APRIORI}}\\[0.4cm]
{\Large \textbf{Môn học: Data Mining}}\\[1.5cm]

% ===== Instructor =====
\begin{flushleft}
\textbf{Giảng viên phụ trách:} ThS. Trần Quốc Việt
\end{flushleft}

\vspace{1.5cm}

% ===== Semester =====
{\Large \textbf{Học kỳ: 1 / 2025 -- 2026}}\\[2cm]

% ===== Students =====


\begin{flushleft}
\textbf{Danh sách sinh viên thực hiện:}\\[0.4cm]
Lê Đình Phùng -- MSSV: 18130181
\end{flushleft}



\vfill
\end{titlepage}


% =============================================================================
% TABLE OF CONTENTS
% =============================================================================
\tableofcontents
\newpage

% =============================================================================
% CHAPTER 1: GIỚI THIỆU
% =============================================================================
\chapter{GIỚI THIỆU}

\section{Đặt Vấn Đề}

Market Basket Analysis là một kỹ thuật data mining được các nhà bán lẻ sử dụng để hiểu rõ hành vi mua sắm của khách hàng. Thông qua việc phân tích dữ liệu giao dịch, chúng ta có thể phát hiện mối quan hệ giữa các sản phẩm thường được mua cùng nhau.

\textbf{Ứng dụng thực tế:}
\begin{itemize}
    \item \textbf{Tối ưu hóa sắp đặt sản phẩm}: Sắp xếp các sản phẩm thường mua cùng nhau ở gần nhau
    \item \textbf{Cơ hội cross-selling}: Đề xuất sản phẩm bổ sung khi khách hàng mua một sản phẩm
    \item \textbf{Tạo bundle sản phẩm}: Tạo các gói sản phẩm khuyến mãi
    \item \textbf{Quản lý tồn kho}: Dự báo nhu cầu sản phẩm chính xác hơn
\end{itemize}

\section{Dataset: Groceries}

\textbf{Mô tả dataset:}
\begin{itemize}
    \item Nguồn: Groceries dataset từ Machine Learning with R
    \item Dữ liệu giao dịch từ một cửa hàng tạp hóa
    \item Mỗi giao dịch đại diện cho giỏ hàng của khách hàng
    \item Chứa một hoặc nhiều mặt hàng trong mỗi transaction
\end{itemize}

\textbf{Thông tin dataset:}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Chỉ Số} & \textbf{Giá Trị} \\
\hline
Total Samples & 6866 giao dịch \\
Total Products & 161 mặt hàng khác nhau \\
Average Items/Transaction & 5.74 items \\
Duplicate Rate & 28.71\% \\
Data Reduction & 30.19\% \\
\hline
\end{tabular}
\caption{Thống kê Dataset}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth,height=0.5\textheight,keepaspectratio]{01_individual_product_occurrence}
\caption{Individual Product Occurrence}
\end{figure}

% =============================================================================
% CHAPTER 2: CƠ SỞ LÝ THUYẾT
% =============================================================================
\chapter{CƠ SỞ LÝ THUYẾT VÀ CÔNG NGHỆ SỬ DỤNG}

\section{Tổng Quan Về Apriori Algorithm}

\textbf{Apriori algorithm} là thuật toán cổ điển cho frequent itemset mining và association rule learning. Nó được đề xuất bởi Agrawal và Srikant vào năm 1994.

\textbf{Nguyên tắc hoạt động:}

\begin{quote}
\textit{Tất cả các tập con của một frequent itemset cũng phải là frequent}
\end{quote}

Đây là nguyên tắc nền tảng giúp Apriori giảm thiểu không gian tìm kiếm bằng cách loại bỏ các candidate itemsets không có khả năng trở thành frequent.

\section{Các Bước Thuật Toán}
\textbf{}

\textbf{Bước 1: Initialization}
\begin{itemize}
    \item Thiết lập ngưỡng support tối thiểu (minimum support threshold)
    \item Xác định các tham số khác (minimum confidence, etc.)
\end{itemize}

\textbf{Bước 2: Generate Candidates}
\begin{itemize}
    \item Tạo itemsets có kích thước k (k-itemsets)
    \item Kết hợp các frequent (k-1)-itemsets để tạo candidate k-itemsets
\end{itemize}

\textbf{Bước 3: Prune}
\begin{itemize}
    \item Loại bỏ itemsets dưới ngưỡng support tối thiểu
    \item Áp dụng nguyên tắc Apriori để loại bỏ sớm các candidates không phù hợp
\end{itemize}

\textbf{Bước 4: Repeat}
\begin{itemize}
    \item Tăng k và lặp lại cho đến khi không tìm thấy frequent itemsets nào nữa
\end{itemize}

\section{Các Chỉ Số Đánh Giá}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Chỉ Số} & \textbf{Ký Hiệu} & \textbf{Công Thức} \\
\hline
Support & supp(A) & P(A) = count(A) / N \\
Confidence & conf(A$\to$B) & P(B|A) = P(A$\cup$B) / P(A) \\
Lift & lift(A$\to$B) & P(A$\cup$B) / (P(A) $\times$ P(B)) \\
Leverage & lev(A$\to$B) & P(A$\cup$B) - P(A) $\times$ P(B) \\
Conviction & conv(A$\to$B) & (1 - P(B)) / (1 - conf) \\
\hline
\end{tabular}
\caption{Các Chỉ Số Đánh Giá Association Rules}
\end{table}

\textbf{Giải thích:}
\begin{itemize}
    \item \textbf{Support}: Cho biết itemset xuất hiện bao nhiêu phần trăm trong tất cả transactions
    \item \textbf{Confidence}: Độ tin cậy của quy tắc association
    \item \textbf{Lift > 1}: A và B xuất hiện cùng nhau nhiều hơn mong đợi (tương quan dương)
    \item \textbf{Lift = 1}: A và B độc lập
    \item \textbf{Lift < 1}: A và B có xu hướng không xuất hiện cùng nhau (tương quan âm)
\end{itemize}

\section{Pipeline Xử Lý Dữ Liệu}
\textbf{}

\textbf{Bước 1: Load Transaction Data}
\begin{lstlisting}[language=Python]
from csv import reader

with open(filepath, 'r') as csv_file:
    csv_reader = reader(csv_file)
    groceries = [row for row in csv_reader]
\end{lstlisting}

\textbf{Bước 2: Encode Transactions}
\begin{lstlisting}[language=Python]
from mlxtend.preprocessing import TransactionEncoder

encoder = TransactionEncoder()
transactions = encoder.fit(groceries).transform(groceries)
itemsets = pd.DataFrame(transactions, columns=encoder.columns_)
\end{lstlisting}

\textbf{Quy trình encoding:}
\begin{itemize}
    \item Chuyển đổi danh sách transactions thành ma trận nhị phân
    \item Mỗi cột đại diện cho một item
    \item Mỗi hàng đại diện cho một transaction
    \item Giá trị 1: item có mặt trong transaction
    \item Giá trị 0: item không có mặt
\end{itemize}

\section{Lựa Chọn Tham Số}

\textbf{Minimum Support Calculation:}
\begin{lstlisting}[language=Python]
minimum_support_threshold = round((30/n_rows) * 5, 5)
\end{lstlisting}

\textbf{Các tham số sử dụng:}
\begin{itemize}
    \item \textbf{Minimum support}: Tính toán động dựa trên kích thước dataset = 0.02185
    \item \textbf{Minimum confidence}: 0.25 (25\%)
    \item \textbf{Rationale}: Cân bằng giữa việc phát hiện các pattern có ý nghĩa và lọc nhiễu
\end{itemize}

\section{Data Cleaning Process}

\textbf{Script thực hiện 7 bước làm sạch dữ liệu:}

\begin{enumerate}
    \item \textbf{Initial Statistics}
    \begin{itemize}
        \item Đếm số transactions và items ban đầu
        \item Tính toán trung bình items per transaction
    \end{itemize}

    \item \textbf{Remove Empty Items}
    \begin{itemize}
        \item Loại bỏ khoảng trắng
        \item Loại bỏ items rỗng
        \item Giữ lại chỉ non-empty transactions
    \end{itemize}

    \item \textbf{Remove Duplicates}
    \begin{itemize}
        \item Sử dụng set-based deduplication
        \item Sort transactions để đảm bảo consistency
        \item Đếm số lượng duplicates bị loại bỏ: 2824 transactions
    \end{itemize}

    \item \textbf{Item Frequency Analysis}
    \begin{itemize}
        \item Đếm tần suất xuất hiện của mỗi item
        \item Hiển thị top 10 items phổ biến nhất
        \item Hiển thị bottom 10 items hiếm nhất
    \end{itemize}

    \item \textbf{Filter Infrequent Items}
    \begin{itemize}
        \item Ngưỡng: items xuất hiện < 0.1\% transactions
        \item Loại bỏ noise và rare items
        \item Giảm chiều dữ liệu
    \end{itemize}

    \item \textbf{Filter Small Transactions}
    \begin{itemize}
        \item Loại bỏ transactions có < 2 items
        \item Single-item transactions không tạo được association rules
    \end{itemize}

    \item \textbf{Final Statistics}
    \begin{itemize}
        \item Tổng kết sau khi làm sạch
        \item Tính \% data reduction: 30.19\%
    \end{itemize}
\end{enumerate}

\section{Công Nghệ Sử Dụng}

\textbf{Ngôn ngữ lập trình:} Python 3.x
\begin{itemize}
    \item Được chọn nhờ sự linh hoạt và thư viện phong phú cho data mining
\end{itemize}

\textbf{Thư viện chính:}
\begin{itemize}
    \item \textbf{mlxtend}: Cung cấp implementation cho Apriori, FP-Growth, FP-Max
    \item \textbf{pandas}: Xử lý dữ liệu dạng bảng
    \item \textbf{numpy}: Tính toán khoa học
    \item \textbf{TransactionEncoder}: Encode transaction data sang binary format
    \item \textbf{plotly}: Trực quan hóa dữ liệu tương tác
\end{itemize}

% =============================================================================
% CHAPTER 3: HIỆN THỰC VÀ KẾT QUẢ
% =============================================================================
\chapter{HIỆN THỰC VÀ KẾT QUẢ}

\section{Frequent Itemset Mining}

\textbf{Triển khai Apriori:}
\begin{lstlisting}[language=Python]
from mlxtend.frequent_patterns import apriori
// minimum_support_threshold = 0.02185
freq_itemsets = apriori(itemsets, minimum_support_threshold, use_colnames=True)
\end{lstlisting}

\textbf{Kết quả:}
\begin{itemize}
    \item Số frequent itemsets tìm được: 173
    \item Độ dài tối đa của itemset: 3 items
    \item Support range: 0.02185 - 0.32348
\end{itemize}

\section{Top Frequent Items}

\begin{table}[H]
\centering
\begin{tabular}{|c|l|c|c|}
\hline
\textbf{Xếp Hạng} & \textbf{Sản Phẩm} & \textbf{Support Count} & \textbf{Support \%} \\
\hline
1 & Whole milk & 2222 & 31.69\% \\
2 & Other vegetables & 1766 & 25.19\% \\
3 & Rolls/buns & 1483 & 21.15\% \\
4 & Soda & 1372 & 19.57\% \\
5 & Yogurt & 1264 & 18.03\% \\
\hline
\end{tabular}
\caption{Top 5 Frequent Items}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth,height=0.5\textheight,keepaspectratio]{02_top_20_frequent_products}
\caption{Top 20 Frequent Products}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth,height=0.4\textheight,keepaspectratio]{03_item_frequency_distribution}
\caption{Item Frequency Distribution}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth,height=0.5\textheight,keepaspectratio]{04_top_10_products_pie_chart}
\caption{Top 10 Products Distribution}
\end{figure}

\section{Association Rules Được Phát Hiện}

\textbf{Thống kê:}
\begin{itemize}
    \item Total Rules Generated: 90
    \item Minimum Confidence: 0.25
    \item Minimum Support: 0.02185
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth,height=0.5\textheight,keepaspectratio]{05_support_vs_confidence_scatter}
\caption{Support vs Confidence Scatter}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth,height=0.5\textheight,keepaspectratio]{06_top_20_rules_by_lift}
\caption{Top 20 Rules by Lift}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth,height=0.4\textheight,keepaspectratio]{07_rules_metrics_distribution_boxplot}
\caption{Rules Metrics Distribution}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth,height=0.5\textheight,keepaspectratio]{08_metrics_correlation_heatmap}
\caption{Metrics Correlation Heatmap}
\end{figure}

% =============================================================================
% CHAPTER 4: SO SÁNH HIỆU SUẤT
% =============================================================================
\chapter{SO SÁNH HIỆU SUẤT}

\section{So Sánh Các Thuật Toân}

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Algorithm} & \textbf{Itemsets} & \textbf{Time (s)} & \textbf{Đặc Điểm} \\
\hline
Apriori (Standard) & 173 & 0.0600 & Baseline, đơn giản \\
FP-Growth & 173 & 2.3068 & Tree-based, compact \\
FP-Max & 131 & 2.0583 & Maximal itemsets \\
Sampling & 25 & 0.0351 & Nhanh, approximate \\
DHP (Hash-based) & 169 & 0.1932 & Hash pruning \\
Transaction Reduction & 175 & 0.0736 & Memory-efficient \\
ECLAT (Vertical) & 174 & 0.0683 & Tid-lists format \\
DIC (Dynamic Counting) & 202 & 3.4055 & Interleaved counting \\
Partitioning & 173 & 0.8112 & Divide \& conquer \\
\hline
\end{tabular}
\caption{So Sánh Các Thuật Toán Frequent Itemset Mining}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth,height=0.5\textheight,keepaspectratio]{09_algorithm_execution_time}
\caption{Algorithm Execution Time Comparison}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth,height=0.5\textheight,keepaspectratio]{10_frequent_itemsets_count}
\caption{Frequent Itemsets Count}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth,height=0.5\textheight,keepaspectratio]{11_time_efficiency_scatter}
\caption{Time Efficiency Scatter}
\end{figure}

\textbf{Phân tích:}
\begin{itemize}
    \item Apriori: Đơn giản, dễ hiểu nhưng kém hiệu quả với dataset lớn
    \item FP-Growth: Cân bằng tốt giữa hiệu suất và bộ nhớ
    \item FP-Max: Tối ưu cho applications chỉ cần maximal frequent itemsets
    \item Sampling: Nhanh nhất nhưng không đầy đủ
    \item ECLAT: Hiệu quả cho sparse datasets
\end{itemize}

% =============================================================================
% CHAPTER 5: KẾT LUẬN
% =============================================================================
\chapter{KẾT LUẬN}

\section{Kết Quả Đạt Được}

Apriori algorithm cung cấp một nền tảng vững chắc cho frequent itemset mining và association rule discovery. Mặc dù có những hạn chế về scalability và hiệu suất, các kỹ thuật tối ưu hóa khác nhau có thể cải thiện đáng kể hiệu quả của nó.

\textbf{Các điểm chính:}

\begin{enumerate}
    \item \textbf{Hash-based pruning} giảm chi phí so sánh candidates
    \item \textbf{Transaction reduction} giảm số lần quét database
    \item \textbf{Partitioning} cho phép xử lý tiết kiệm bộ nhớ
    \item \textbf{Parallelization} tận dụng các kiến trúc multi-core hiện đại
\end{enumerate}

\textbf{Kết quả thực nghiệm:}

Với Groceries dataset:
\begin{itemize}
    \item \textbf{FP-Growth} thể hiện hiệu suất vượt trội so với Apriori truyền thống
    \item \textbf{FP-Max} là lựa chọn tốt nhất khi chỉ cần maximal itemsets
    \item \textbf{ECLAT} hiệu quả cho sparse datasets
    \item Các cải tiến đề xuất có thể giảm 30-50\% execution time
\end{itemize}

\section{Hạn Chế Của Apriori}

\textbf{}
\textbf{1. Multiple Database Scans}
\begin{itemize}
    \item Mỗi lần lặp yêu cầu quét toàn bộ database
    \item Với k lần lặp, cần k lần quét database
    \item Tốn kém I/O operations với dataset lớn
\end{itemize}

\textbf{2. Large Candidate Set}
\begin{itemize}
    \item Sự tăng trưởng theo cấp số nhân của candidate itemsets
    \item Với k items, có $2^k - 1$ possible itemsets
    \item Tốn nhiều bộ nhớ để lưu trữ và tính toán
\end{itemize}

\textbf{3. Memory Usage}
\begin{itemize}
    \item Lưu trữ tất cả candidates trong bộ nhớ
    \item Khó scale với datasets lớn
    \item Có thể gây memory overflow
\end{itemize}

\textbf{4. Computational Cost}
\begin{itemize}
    \item Việc sinh candidates tốn kém
    \item Counting support cho mỗi candidate
    \item Pruning chưa tối ưu
\end{itemize}

\section{Các Chiến Lược Cải Tiến}

\subsection{Hash-Based Technique (DHP)}
\textbf{}


\textbf{Concept:}
\begin{itemize}
    \item Hash các candidate itemsets để giảm chi phí so sánh
    \item Sử dụng hash function để map candidates vào buckets
\end{itemize}

\textbf{Benefit:}
\begin{itemize}
    \item Lọc các infrequent itemsets sớm hơn
    \item Giảm số lượng candidates cần kiểm tra
    \item Tăng tốc độ tính toán
\end{itemize}

\subsection{Transaction Reduction}
\textbf{}

\textbf{Concept:}
\begin{itemize}
    \item Loại bỏ các transactions không chứa frequent k-itemsets
    \item Chỉ giữ lại transactions có giá trị cho các lần lặp tiếp theo
\end{itemize}

\textbf{Benefit:}
\begin{itemize}
    \item Giảm kích thước database cho các lần lặp tiếp theo
    \item Ít tốn kém I/O operations
    \item Tăng tốc độ processing
\end{itemize}

\subsection{Partitioning}
\textbf{}

\textbf{Concept:}
\begin{itemize}
    \item Chia database thành các partitions nhỏ hơn
    \item Mỗi partition có thể xử lý độc lập trong bộ nhớ
\end{itemize}

\textbf{Benefit:}
\begin{itemize}
    \item Xử lý các partitions độc lập trong bộ nhớ
    \item Cho phép parallel processing
    \item Scale tốt với dataset lớn
\end{itemize}

\subsection{Sampling}
\textbf{}

\textbf{Concept:}
\begin{itemize}
    \item Mine trên một subset (sample) của dữ liệu
    \item Sử dụng statistical techniques để extrapolate
\end{itemize}

\textbf{Benefit:}
\begin{itemize}
    \item Giảm đáng kể chi phí tính toán
    \item Nhanh chóng thu được kết quả sơ bộ
    \item Phù hợp cho exploratory analysis
\end{itemize}

\subsection{Dynamic Itemset Counting (DIC)}
\textbf{}

\textbf{Concept:}
\begin{itemize}
    \item Thêm mới candidate itemsets một cách động
    \item Không đợi đến lượt của k-itemsets
\end{itemize}

\textbf{Benefit:}
\begin{itemize}
    \item Ít database scans hơn
    \item Tăng tốc convergence
    \item Giảm total execution time
\end{itemize}

\subsection{Vertical Format (ECLAT)}
\textbf{}

\textbf{Concept:}
\begin{itemize}
    \item Sử dụng vertical data format thay vì horizontal
    \item Mỗi item có danh sách transaction IDs (tid-list)
\end{itemize}

\textbf{Benefit:}
\begin{itemize}
    \item Intersection của tid-lists rất nhanh
    \item Đặc biệt hiệu quả cho sparse datasets
    \item Depth-first search
\end{itemize}

\section{Khuyến Nghị Sử Dụng}
\textbf{}

\textbf{1. Small Datasets (< 10K transactions)}
\begin{itemize}
    \item \textbf{Algorithm}: Apriori
    \item \textbf{Lý do}: Đơn giản, dễ hiểu, dễ implement
    \item \textbf{Thích hợp}: Teaching, prototyping
\end{itemize}

\textbf{2. Medium Datasets (10K - 1M transactions)}
\begin{itemize}
    \item \textbf{Algorithm}: FP-Growth
    \item \textbf{Lý do}: Hiệu suất tốt hơn, scalable
    \item \textbf{Thích hợp}: Production systems
\end{itemize}

\textbf{3. Large Datasets (> 1M transactions)}
\begin{itemize}
    \item \textbf{Algorithm}: FP-Max hoặc Parallel Apriori
    \item \textbf{Lý do}: Tối ưu bộ nhớ, có thể parallelize
    \item \textbf{Thích hợp}: Big data applications
\end{itemize}

\textbf{4. Real-time Applications}
\begin{itemize}
    \item \textbf{Algorithm}: Sampling-based approaches
    \item \textbf{Lý do}: Nhanh, suitable cho streaming data
    \item \textbf{Thích hợp}: Real-time recommendations
\end{itemize}

% =============================================================================
% REFERENCES
% =============================================================================
\chapter{TÀI LIỆU THAM KHẢO}

\section*{Nghiên Cứu Gốc}

\begin{enumerate}
    \item Agrawal, R., \& Srikant, R. (1994). ``Fast Algorithms for Mining Association Rules in Large Databases.'' \textit{Proceedings of the 20th International Conference on Very Large Data Bases (VLDB)}.

    \item Han, J., Pei, J., \& Yin, Y. (2000). ``Mining Frequent Patterns without Candidate Generation.'' \textit{Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data}.
\end{enumerate}

\section*{Sách Tham Khảo}

\begin{enumerate}
    \item Borgelt, C. (2012). ``Frequent Item Set Mining.'' \textit{Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery}, 2(6), 437-456.

    \item Tan, P. N., Steinbach, M., \& Kumar, V. (2006). \textit{Introduction to Data Mining}. Pearson Education.
\end{enumerate}

\section*{Tài Liệu Trực Tuyến}

\begin{enumerate}
    \item mlxtend Documentation: \url{http://rasbt.github.io/mlxtend/}

    \item Scikit-learn Documentation: \url{https://scikit-learn.org/}

    \item Plotly Documentation: \url{https://plotly.com/python/}
\end{enumerate}

\section*{Dataset}

\begin{enumerate}
    \item Groceries Dataset: \url{https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/groceries.csv}
\end{enumerate}

\end{document}
